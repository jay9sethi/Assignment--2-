{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EAJeVoyVoAq_",
        "outputId": "aa1f13f1-a465-4280-e4a0-eb844caea6fd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Status Code: 200\n",
            "Number of Titles: 0\n",
            "Number of Years: 0\n",
            "Number of Ratings: 0\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "\n",
        "# URL of the IMDb Top 250 movies page\n",
        "url = 'https://www.imdb.com/chart/top'\n",
        "\n",
        "# Headers to make the request look like it's coming from a browser\n",
        "headers = {\n",
        "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}\n",
        "\n",
        "# Send a GET request to the URL with headers\n",
        "response = requests.get(url, headers=headers)\n",
        "print(\"Status Code:\", response.status_code)  # Check if the request was successful\n",
        "\n",
        "# Parse the HTML content of the page with BeautifulSoup\n",
        "soup = BeautifulSoup(response.content, 'html.parser')\n",
        "\n",
        "# Find the containers for the movie details\n",
        "movies = soup.select('td.titleColumn')\n",
        "ratings = soup.select('td.imdbRating strong')\n",
        "\n",
        "# Lists to store the extracted data\n",
        "titles = []\n",
        "years = []\n",
        "imdb_ratings = []\n",
        "\n",
        "# Extract the data\n",
        "for movie in movies:\n",
        "    title = movie.find('a').get_text()\n",
        "    year = movie.find('span', class_='secondaryInfo').get_text().strip('()')\n",
        "    titles.append(title)\n",
        "    years.append(year)\n",
        "    print(f\"Title: {title}, Year: {year}\")  # Debugging print\n",
        "\n",
        "for rating in ratings:\n",
        "    imdb_ratings.append(rating.get_text())\n",
        "    print(f\"Rating: {rating.get_text()}\")  # Debugging print\n",
        "\n",
        "# Check if data lists are of the same length\n",
        "print(f\"Number of Titles: {len(titles)}\")\n",
        "print(f\"Number of Years: {len(years)}\")\n",
        "print(f\"Number of Ratings: {len(imdb_ratings)}\")\n",
        "\n",
        "# Create a DataFrame\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a DataFrame with the extracted data\n",
        "df = pd.DataFrame({\n",
        "    'Title': titles,\n",
        "    'Year': years,\n",
        "    'Rating': imdb_ratings\n",
        "})\n",
        "\n",
        "# Save the DataFrame to a CSV file\n",
        "df.to_csv('imdb_top_250.csv', index=False)\n",
        "\n",
        "print('Scraping complete. Data saved to imdb_top_250.csv')\n"
      ],
      "metadata": {
        "id": "aWXxPUIloJZ2",
        "outputId": "90fb6738-4ff4-4d2b-cec9-b9d35a2973c1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scraping complete. Data saved to imdb_top_250.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pukQx6MHoLy_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}